{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Python Exercises\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All).  You can speak with others regarding the assignment but all work must be your own. \n",
    "\n",
    "\n",
    "### This is a 30 point assignment graded from answers to questions and automated tests that should be run at the bottom. Be sure to clearly label all of your answers and commit final tests at the end. If you attempt to fake passing the tests you will receive a 0 on the assignment and it will be considered an ethical violation. (Note, not all questions have tests).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Emma Prescott\"\n",
    "COLLABORATORS = \"Andrew Lashombe & Guannan Wang\"  #You can speak with others regarding the assignment, but all typed work must be your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "**If you attempt to fake passing the tests you will receive a 0 on the assignment and it will be considered an ethical violation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - For and If.\n",
    "\n",
    "(1). Write a for loop which create a list called `fivetoten` of all numbers from 5 to 10 (inclusive).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"A1\"\n",
    "fivetoten = [ ]\n",
    "for n in range(5,11):\n",
    "    fivetoten.append(n)\n",
    "fivetoten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2). Write a program which uses a for loop and if statements to create a list called `divby7` of all numbers from 1-50 that are divisible by 7.\n",
    "Hint: 14 is divisible by 7 if 14%7==0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 14, 21, 28, 35, 42, 49]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"A2\"\n",
    "divby7 = [ ]\n",
    "for n in range(1, 51):\n",
    "    if n%7==0:\n",
    "        divby7.append(n)\n",
    "divby7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3). Write a program which uses a for loop and if statements create a list `divby7not5` of all numbers which are divisible by 7 but are not a multiple of 5, between 10000 and 10100 (both included). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10003, 10017, 10024, 10031, 10038, 10052, 10059, 10066, 10073, 10087, 10094]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"A3\"\n",
    "divby7not5 = [ ]\n",
    "for n in range(10000, 10101):\n",
    "    if n%7==0 and n%5!=0:\n",
    "        divby7not5.append(n)\n",
    "divby7not5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - Functions\n",
    "\n",
    "(4). Create a function `divby2` that accepts a list and returns all values from that list that are divisible by 2.  For example, passing the list  `numbers = [3, 12, 91, 33, 21, 34, 54, 34, 34, 54]` should return a list. Generate a new list `divby2` that includes only numbers that are divisible by 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"A4\"\n",
    "def divby2(L):\n",
    "    newL = []\n",
    "    for i in L:\n",
    "        if i%2==0:\n",
    "            newL.append(i)\n",
    "    return newL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 34, 54, 34, 34, 54]\n"
     ]
    }
   ],
   "source": [
    "#Execute this code to assign divby2 to the correct values. \n",
    "numbers = [3, 12, 91, 33, 21, 34, 54, 34, 34, 54]\n",
    "divby2=divby2(numbers)\n",
    "print(divby2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Create an external module for your `divby2` function called `myutilities.py`.  Import myutilities as mu, such that that following runs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After importing this should work. \n",
    "#Add code to re-import the module using the example in class\n",
    "\"A5\"\n",
    "import myutilities as mu\n",
    "divby2mod=mu.divby2(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises-Titanic\n",
    "\n",
    "The following exercises will use the titanic data from Kaggle.  I've included it in the input folder just like Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# Let's input them into a Pandas DataFrame\n",
    "train = pd.read_csv(\"./input/train.csv\")\n",
    "test  = pd.read_csv(\"./input/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(6). While we can submit our answer to Kaggle to see how it will perform, we can also utilize our test data to assess accuracy. Accuracy is the percentage of predictions made correctly-i.e., the percentage of people in which our prediction regarding their survival. <br>Create columns in the training dataset `PredEveryoneDies` and `PredGender` with the same predictions which were included in the example notebook (06-intro-kaggle-baseline in the materials repository).   \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"A6\"\n",
    "train['PredEveryoneDies'] = 0\n",
    "train.loc[train['Sex']=='male', 'PredGender'] = 0\n",
    "train.loc[train['Sex']=='female', 'PredGender'] = 1\n",
    "\n",
    "test['PredEveryoneDies'] = 0\n",
    "test.loc[test['Sex']=='male', 'PredGender'] = 0\n",
    "test.loc[test['Sex']=='female', 'PredGender'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOU CAN DO THIS!\n",
    "- For the next question we have to combine a few bits of data. For the first time we will be connecting multiple operations.   \n",
    "- First, you should find out the mathematical definition for accuracy. OK, here is a [link](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification). \n",
    "- Next, consider how you would program accuracy? \n",
    "- Next, try it with some sample data where you know the answer. I've created that below.\n",
    "- Next, hand calculate the accuracy for the sample data.\n",
    "- Next, programatically find the accuracy for the sample data.  How might you do this using the tools that you have?  (a) create a new column where for the Training set `Survived==PredEveryoneDies` it equals 1 if true and 0 if false. (b) Sum the number of 1s and (c)  divide by the total number of records in the training set.  \n",
    "- Finally, turn your calculations of accuracy into a function so you can reuse it in the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = [{'predicted': 1, 'actual': 1},\n",
    "         {'predicted': 1,  'actual': 0},\n",
    "         {'predicted': 0,  'actual': 1},\n",
    "         {'predicted': 0,  'actual': 0}]\n",
    "#Accuracy Test Program\n",
    "#df = pd.DataFrame(example_data)\n",
    "#for i in df:\n",
    " #   df['accuracytest'] = np.where(df['predicted'] == df['actual'], 1, 0) \n",
    "#df\n",
    "\n",
    "#Accuracy Test Function\n",
    "def AccTest(dframe, column1, column2, newcolumn):\n",
    "    dframe[newcolumn] = np.where(dframe[column1] == dframe[column2], 1, 0)\n",
    "    Acc = (sum(dframe[newcolumn])/dframe[newcolumn].count())*100\n",
    "    return Acc\n",
    "\n",
    "a = AccTest(pd.DataFrame(example_data), 'predicted', 'actual', 'accuracytest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Use your function to create varaibles `AccEveryoneDies` and `AccGender`.  `AccEveryoneDies` should be the accuracy of the EveryoneDies model in the Train dataset. Similarly, `AccGender` is the a accuracy of the Gender (women survive) model in the Train dataset. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.6161616162\n",
      "78.6756453423\n"
     ]
    }
   ],
   "source": [
    "\"A7\"\n",
    "AccEveryoneDies = AccTest(train, 'Survived', 'PredEveryoneDies', 'AccEveryoneDies')\n",
    "AccGender = AccTest(train, 'Survived', 'PredGender', 'AccGender')\n",
    "print(AccEveryoneDies)\n",
    "print(AccGender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8). Create a `generate_submission` function that accepts a DataFrame, a target column, and a filename and writes out the submission file with just the `passengerID` and the `Survived` columns, where the survived column is equal to the target column. It should then return a DataFrame with the `passengerID` and the `Survived` columns.\n",
    "\n",
    "Executeing the following:\n",
    "`submitdie = generate_submission(train, 'PredEveryoneDies', 'submiteveryonedies.csv')`\n",
    "\n",
    "Should return a dataframe with just `passengerID` and the `Survived` column.  \n",
    "\n",
    "Create a prediction file for the \"PredEveryoneDies\" model using the test dataset and upload it to Kaggle.  Put that screenshot in this repository of what happens. Sometimes Kaggle won't give you a score if the exact same file has been submitted by someone else.  Don't worry about that. \n",
    "\n",
    "The syntax for including a markdown picture is shown below. \n",
    "\n",
    "```\n",
    "![]myscreenshot.png\n",
    "```\n",
    "\n",
    "You will have to change the cell type to a markdown cell below.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(df, tcolumn, fname):\n",
    "    submission = df.loc[:,['PassengerId', tcolumn]]\n",
    "    submission.columns = ['PassengerId', 'Survived']\n",
    "    submission.to_csv(fname, index=False)\n",
    "    return submission\n",
    "\n",
    "submitdie = generate_submission(test, 'PredEveryoneDies', 'submiteveryonedies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](everyonedies.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(9). In our initial calculation of the `PredGender` column, we made our prediction based on whether the individual was male or female.  In accordance to the [women and children first](https://en.wikipedia.org/wiki/Women_and_children_first) protocol, we hypothesize that our model could be improved by including whether the individual was a child in addition to gender. We also have a question, what age to use to determine \"child\"? (People weren't likely to check for IDs.)  We will check 2 ages...<13 and <18 (somewhat arbitrary but have to start somewhere) and see which yields a better accuracy. <br>\n",
    "\n",
    "*After* coding survival based on gender, update your recommendation to prediction in the training dataset survival based on *age.* In other words, your model should predict that a male child would survive. If you first code for age and then code by gender, the prediction will be off. <br> \n",
    "\n",
    "Specifically:\n",
    "\n",
    "`train['PredGenderAge13']` should be the prediction incorporating both Gender and whether Age < 13 (i.e., <13 survived while >=13 died)  <br>\n",
    "`train['PredGenderAge18']` should be the prediction incorporating both Gender and whether Age < 18 (i.e., <18 survived while >=18 died).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaced null ages with mean age\n",
    "aveage=train.Age.mean()\n",
    "aveage= int(aveage)\n",
    "train.loc[train.Age.isnull(),\"Age\"]=aveage\n",
    "\n",
    "\"A9\"\n",
    "train['PredGenderAge13'] = np.where((train['Sex']=='female') | (train['Age']<13.0), 1, 0)\n",
    "train['PredGenderAge18'] = np.where((train['Sex']=='female') | (train['Age']<18.0), 1, 0)\n",
    "\n",
    "#Apply to test dataset\n",
    "aveage=test.Age.mean()\n",
    "aveage= int(aveage)\n",
    "test.loc[test.Age.isnull(),\"Age\"]=aveage\n",
    "\n",
    "test['PredGenderAge13'] = np.where((test['Sex']=='female') | (test['Age']<13.0), 1, 0)\n",
    "test['PredGenderAge18'] = np.where((test['Sex']=='female') | (test['Age']<18.0), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10). Calculate the accuracy for your new predictions.  Use `PredGenderAge13` in the training set to calculate `AccGenderAge13` (you can use your function again!) and `PredGenderAge18` to calcuate `AccGenderAge18`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.2368125701\n",
      "77.3288439955\n"
     ]
    }
   ],
   "source": [
    "\"A10\"\n",
    "AccGenderAge13 = AccTest(train, 'Survived', 'PredGenderAge13', 'AccGenderAge13')\n",
    "AccGenderAge18 = AccTest(train, 'Survived', 'PredGenderAge18', 'AccGenderAge18')\n",
    "\n",
    "print(AccGenderAge13)\n",
    "print(AccGenderAge18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11). You should find that the `AccGenderAge13` is better (has a higher accuracy) than `AccGenderAge18`. Create a new column `child` in the `test` and `train` DataFrames that is 1 if `Age < 13` and `0` otherwise. This is a feature. We will talk more about features next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['child'] = np.where(train['Age'] < 13, 1, 0)\n",
    "test['child'] = np.where(test['Age'] <13, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12). Create a prediction file for the \"women and children first\" model in using the test dataset and upload it to Kaggle. Go through the process of uploading it to Kaggle. Put that screenshot in this repository of what happens. Sometimes Kaggle won't give you a score if the exact same file has been submitted by someone else.  Don't worry about that.  The syntax for including a markdown picture is shown below.  \n",
    "\n",
    "```\n",
    "![]myscreenshot.png\n",
    "```\n",
    "\n",
    "You will have to change the cell type to a markdown cell below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitgenderage = generate_submission(test, 'PredGenderAge13', 'womenandchildren.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](womenchildren.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (13) How would you compare the final \"women and children\" first model with the initial baseline mode (\"everyone died)\" ?  \n",
    "Include change in accruacy and how you would interpret this intial analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Baseline: 61.616162 percent\n",
      "Accuracy of Women & Children (age 13): 79.236813 percent\n",
      "Change in Accuracy: -17.620651 percent change\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As you can see, the change in accuracy is -17.62 percent which means the Baseline model is 17.62 percent less accurate than the Women & Children (age 13). Or vice versa the Women & Children model is 17.62 percent more accurate than the Baseline model.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChangeInAcc = float(AccEveryoneDies - AccGenderAge13)\n",
    "print('Accuracy of Baseline: %f percent'%(AccEveryoneDies))\n",
    "print('Accuracy of Women & Children (age 13): %f percent' %(AccGenderAge13))\n",
    "print('Change in Accuracy: %f percent change' %(ChangeInAcc))\n",
    "\n",
    "'''As you can see, the change in accuracy is -17.62 percent which means the Baseline model is 17.62 percent less accurate than the Women & Children (age 13). Or vice versa the Women & Children model is 17.62 percent more accurate than the Baseline model.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Tests\n",
    "- These final tests will confirm you did exercises correctly. \n",
    "- First you need to install the ipython_unittest package \n",
    "- Then you load the extensions.\n",
    "- Then you run the tests.  \n",
    "- Try to work through the exercises, inspecting your own results.  Then confirm with the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes ipython_unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ipython_unittest\n",
    "#This runs tests against your b array.  If you complete the assingment correctly, you will pass the tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the cells below before submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/unittest.status+json": {
       "color": "yellow",
       "message": "",
       "previous": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/unittest.status+json": {
       "color": "lightgreen",
       "message": "...............\n----------------------------------------------------------------------\nRan 15 tests in 0.008s\n\nOK\n",
       "previous": 0
      },
      "text/plain": [
       "Success"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............\n",
      "----------------------------------------------------------------------\n",
      "Ran 15 tests in 0.008s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=15 errors=0 failures=0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%unittest_main\n",
    "class TestExercise3(unittest.TestCase):\n",
    "    def test_forif1(self):\n",
    "        self.assertTrue(fivetoten == [5,6,7,8,9,10])\n",
    "    def test_forif2(self):\n",
    "        self.assertTrue(divby7 == [7,14,21,28,35,42,49])\n",
    "    def test_forif(self):\n",
    "        self.assertTrue(divby7not5 == [10003, 10017, 10024, 10031, 10038, 10052, 10059, 10066, 10073, 10087, 10094])\n",
    "    def test_functions(self):\n",
    "        self.assertTrue(divby2 == [12, 34, 54, 34, 34, 54])\n",
    "    def test_functions(self):\n",
    "        self.assertTrue(divby2mod == [12, 34, 54, 34, 34, 54])\n",
    "    def test_titanic1(self):\n",
    "        self.assertAlmostEqual(AccEveryoneDies, 61.6161616162)\n",
    "    def test_titanic2(self):\n",
    "        self.assertAlmostEqual(AccGender, 78.6756453423)\n",
    "    def test_titanic3(self):\n",
    "        self.assertAlmostEqual(train['PredEveryoneDies'].mean(), 0.0)\n",
    "    def test_titanic4(self):\n",
    "        self.assertAlmostEqual(train['PredGender'].mean(), 0.35241301908)\n",
    "    def test_titanic5(self):\n",
    "        self.assertTrue(['PassengerId', 'Survived']==list(pd.read_csv('submiteveryonedies.csv').columns.values))\n",
    "    def test_titanic6(self):\n",
    "        self.assertAlmostEqual(train['PredGenderAge13'].mean(), 0.393939393939)\n",
    "    def test_titanic7(self):\n",
    "        self.assertAlmostEqual(train['PredGenderAge18'].mean(), 0.417508417508)\n",
    "    def test_titanic8(self):\n",
    "        self.assertAlmostEqual(AccGenderAge13, 79.2368125701)\n",
    "    def test_titanic9(self):\n",
    "        self.assertAlmostEqual(AccGenderAge18, 77.3288439955)\n",
    "    def test_titanic10(self):\n",
    "        self.assertTrue(train['child'].sum()==69)\n",
    "    def test_titanic11(self):\n",
    "        self.assertTrue(test['child'].sum()==25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a collection of all of the tests from the exercises above. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
